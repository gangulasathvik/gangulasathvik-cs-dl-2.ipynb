# -*- coding: utf-8 -*-
"""cs dl-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ifZ5hGpYzRcBG6goaZv0YkkxfYyfkT4i
"""

# Importing NumPy library for numerical operations on arrays
import numpy as np

# Importing Matplotlib library for plotting graphs and images
import matplotlib.pyplot as plt

# Importing TensorFlow library for deep learning tasks
import tensorflow as tf

# Importing the Keras submodule from TensorFlow
from tensorflow import keras

# Importing Keras backend module for low-level operations
import keras.backend as K

# Importing specific layers from Keras for building neural network architecture
from tensorflow.keras.layers import Input, Flatten, Dense, Lambda, Reshape, Conv2D, Conv2DTranspose

# Commented out IPython magic to ensure Python compatibility.
# Magic command to specify that you want to use TensorFlow version 2.x
# %tensorflow_version 2.x

# Magic command to enable inline plotting in Jupyter notebooks or Colab
# %matplotlib inline

"""## Load and Process the Dataset"""

# Loading the Fashion MNIST dataset into variables (X_train, y_train) and (X_test, y_test)
(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()

# Printing the shapes of training and test datasets along with their corresponding labels
print(X_train.shape, '\t', y_train.shape)
print(X_test.shape, '\t', y_test.shape)

"""The pixel values in the data lie between 0 and 255. So, we need to normalise them"""

# Scaling the pixel values of the training data in X_train to the range [0, 1] by dividing by 255
X_train = X_train.astype('float32') / 255

# Scaling the pixel values of the test data in X_test to the range [0, 1] by dividing by 255
X_test = X_test.astype('float32') / 255

"""Now, we use the .`reshape()` fucntion to reshape our data in the format expected by TensorFlow layer i.e., (no of samples, width, height, no of channels)"""

# Reshaping the training data array X_train to have dimensions (-1, 28, 28, 1)
# The -1 in the shape indicates that the size of that dimension should be inferred to maintain the total number of elements
# The dimensions (-1, 28, 28, 1) represent: number of samples, height, width, and number of channels (in this case, 1 channel for grayscale images)
X_train = X_train.reshape((-1, 28, 28, 1))

# Reshaping the test data array X_test to have dimensions (-1, 28, 28, 1)
# The -1 in the shape indicates that the size of that dimension should be inferred to maintain the total number of elements
# The dimensions (-1, 28, 28, 1) represent: number of samples, height, width, and number of channels (in this case, 1 channel for grayscale images)
X_test = X_test.reshape((-1, 28, 28, 1))

"""## Visualization of Samples
We plot a few random observations
"""

plt.figure(1)                # Create a new figure
plt.subplot(221)             # Create subplot 1
plt.imshow(X_train[20][:,:,0])  # Display 20th sample
plt.subplot(222)             # Create subplot 2
plt.imshow(X_train[300][:,:,0]) # Display 300th sample
plt.subplot(223)             # Create subplot 3
plt.imshow(X_train[4000][:,:,0])# Display 4000th sample
plt.subplot(224)             # Create subplot 4
plt.imshow(X_train[5000][:,:,0])# Display 5000th sample
plt.show()                   # Show the plots

"""## Model Architecture
We now design our VAE model; which involves of an encoder, the latent space and a decoder. Model implementation wise, the latent space can be considered to be a part of the encoder

### Encoder
"""

enc_input = Input(shape=(28,28,1), name='encoder input')  # Define encoder input layer
x = Conv2D(128, 5, padding='same', activation='relu')(enc_input)  # Apply 128 filters of size 5x5 with relu activation
x = Conv2D(64, 3, padding='same', strides=2, activation='relu')(x)  # Apply 64 filters of size 3x3 with relu activation and stride 2
x = Conv2D(64, 3, padding='same', activation='relu')(x)  # Apply 64 filters of size 3x3 with relu activation
x = Conv2D(64, 3, padding='same', activation='relu')(x)  # Apply 64 filters of size 3x3 with relu activation

enc_shape = K.int_shape(x)  # Get the shape of the encoder output

x = Flatten()(x)   # Flatten the input into a 1D array
x = Dense(32)(x)   # Fully connected layer with 32 neurons

"""#### Latent Space"""

latent_dim = 2  # Define the dimensionality of the latent space as 2
z_mean = Dense(latent_dim, name='Z-mean')(x)  # Dense layer to compute mean of the latent space
z_logvar = Dense(latent_dim, name='Z-logvariance')(x)  # Dense layer to compute log variance of the latent space

"""We need to define a function that takes in the mean and log variance parameters and return a random sample from the resulting distribution."""

def sampling(args):
  mean, logvar = args  # Unpack mean and log variance
  eps = K.random_normal([latent_dim])  # Generate random noise from standard normal distribution
  rnd_sam = mean + K.exp(logvar/2) * eps  # Reparameterization trick to sample from the latent space
  return rnd_sam

"""By using a Lambda layer, we can thus define our latent space as shown below"""

# Define the latent space layer using the Lambda layer, applying the sampling function to z_mean and z_logvar.
# The output shape of the layer is specified as latent_dim, representing the dimensionality of the latent space.
# The name of the layer is set to 'latent-space'.
z = Lambda(sampling, output_shape=latent_dim, name='latent-space')([z_mean, z_logvar])

encoder = keras.Model(enc_input, z, name='encoder')  # Create encoder model mapping input to latent space
encoder.summary()  # Print summary of the encoder model

"""### Decoder
Here, we need to take the randomly sampled 2D latent space vector and convert it back to the original format of the image i.e., 28x28 with a single channel
"""

dec_input = Input(shape=(latent_dim,), name='decoder-input')  # Define decoder input layer

true_shape = enc_shape[1:]  # Retrieve true shape of the data after encoding

y = Dense(np.prod(true_shape))(dec_input)  # Fully connected layer to match true shape
y = Reshape(target_shape=true_shape)(y)  # Reshape layer to match true shape
y = Conv2DTranspose(64, 3, padding='same', activation='relu')(y)  # Transposed convolutional layer
y = Conv2DTranspose(64, 3, padding='same', activation='relu')(y)  # Transposed convolutional layer
y = Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu')(y)  # Transposed convolutional layer
y = Conv2DTranspose(128, 5, padding='same', activation='relu')(y)  # Transposed convolutional layer
y = Conv2DTranspose(1, 5, padding='same', activation='relu')(y)  # Transposed convolutional layer

decoder = keras.Model(dec_input, y, name='decoder')  # Create decoder model mapping latent space to output
decoder.summary()  # Print summary of the decoder model

"""### Connecting all components,"""

enc_output = encoder(enc_input)  # Obtain encoder output by passing encoder input through the encoder model
dec_output = decoder(enc_output)  # Obtain decoder output by passing encoder output through the decoder model

vae = keras.Model(enc_input, dec_output, name='VAE')  # Create VAE model mapping encoder input to decoder output
vae.summary()  # Print summary of the VAE model

"""## Training
First, we need to define a custom loss function which trains our model based to improve an error defined as the sum of reconstruction loss and KL-Divergence loss.
"""

def loss_func(z_mean, z_logvar):

    # Define reconstruction loss function for VAE
    def vae_reconstruction_loss(y_true, y_predict):
        reconstruction_loss_factor = 100
        # Calculate mean squared error between true and predicted values
        reconstruction_loss = K.mean(K.square(y_true - y_predict), axis=[1, 2, 3])
        # Scale the reconstruction loss by a factor
        return reconstruction_loss_factor * reconstruction_loss

    # Define KL divergence loss function for VAE
    def vae_kl_loss(z_mean, z_logvar):
        # Calculate KL divergence loss term
        kl_loss = -0.5 * K.sum(1.0 + z_logvar - K.square(z_mean) - K.exp(z_logvar), axis=1)
        return kl_loss

    # Define KL divergence loss function as a metric for monitoring during training
    def vae_kl_loss_metric(y_true, y_predict):
        # Calculate KL divergence loss term
        kl_loss = -0.5 * K.sum(1.0 + z_logvar - K.square(z_mean) - K.exp(z_logvar), axis=1)
        return kl_loss

    # Define overall VAE loss function as a combination of reconstruction and KL divergence losses
    def vae_loss(y_true, y_predict):
        # Calculate reconstruction loss
        reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)
        # Calculate KL divergence loss
        kl_loss = vae_kl_loss(y_true, y_predict)
        # Combine reconstruction and KL divergence losses
        loss = reconstruction_loss + kl_loss
        return loss

    return vae_loss

"""We can now compile and train"""

opt = keras.optimizers.Adam(learning_rate=0.0001)  # Define Adam optimizer with specified learning rate
vae.compile(optimizer=opt, loss=loss_func(z_mean, z_logvar))  # Compile VAE model with optimizer and loss function

# Train the Variational Autoencoder (VAE) model on the training data (X_train) using itself as both input and target
# for 20 epochs with a batch size of 32. Use the validation data (X_test) to evaluate the model's performance during training.
# Store the training metrics and performance in the history object.
history = vae.fit(X_train, X_train, epochs=5, batch_size=32, validation_data=(X_test, X_test))

"""Here, we performed naive hyperparameter tuning and achieved the above results. Whether the above loss is satisfactory or not depends on how well the model can reconstruct a given sample. This can only be gauged by visualising a few test observations.

## Visualization of Test samples
"""

index = int(input())  # Input the index of the sample to visualize

y_pred = vae.predict(X_test)  # Generate predictions using the VAE model

plt.figure(1)  # Create a new figure

# Display original image from the test set
plt.subplot(221)
plt.imshow(X_test[index].reshape(28,28))

# Display reconstructed image using the VAE model
plt.subplot(222)
plt.imshow(y_pred[index].reshape(28,28))

# Display original image from the test set (at index*5)
plt.subplot(223)
plt.imshow(X_test[index*5].reshape(28,28))

# Display reconstructed image using the VAE model (at index*5)
plt.subplot(224)
plt.imshow(y_pred[index*5].reshape(28,28))

plt.show()  # Show the plotted images

"""As seen above, the model is successful in reconstructing the general shape of the clothing item but finer details like text or patters are lost. For our case, this is satisfactory

## Downloading our models
"""

keras.models.save_model(encoder, 'fm_encoder.h5')  # Save the encoder model to a file named 'fm_encoder.h5'
keras.models.save_model(decoder, 'fm_decoder.h5')  # Save the decoder model to a file named 'fm_decoder.h5'
keras.models.save_model(vae, 'fm_vae.h5')  # Save the VAE model to a file named 'fm_vae.h5'

"""## Exploring our Latent Space
The main application of a VAE is to obtain a low dimensional latent space for our data. Theoritically, every vector in this space is a reduced version of some sample in the original feature space. Exploring the latent space may therefore allow us to find weird, unique and interesting images that may be similar to training samples. The resulting visualization would look cooler with human face datasets, cat image datasets etc, but our plots get the point across.
"""

sample_vector = np.array([[3,7]])  # Define a sample vector in the latent space

decoded_example = decoder.predict(sample_vector)  # Generate a decoded example using the decoder model and the sample vector

plt.imshow(decoded_example.reshape(28,28))  # Display the decoded example as an image